{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.zeros(shape=(3,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(initial_value=3.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=9.8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.Variable(0.0)\n",
    "with tf.GradientTape() as tape2:\n",
    "    with tf.GradientTape() as tape1:\n",
    "        s = 4.9 * t * t\n",
    "    v = tape1.gradient(s, t)\n",
    "a = tape2.gradient(v, t)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1000\n",
    "n_features = 5\n",
    "\n",
    "signal_spread = 5\n",
    "noise_spread = 1\n",
    "\n",
    "w_train = tf.random.uniform(shape=(n_features, 1), minval=-signal_spread, maxval=signal_spread)\n",
    "b_train = tf.random.uniform(shape=(1,), minval=-signal_spread, maxval=signal_spread)\n",
    "\n",
    "x_train = tf.random.uniform(shape=(n_train, n_features), minval=-signal_spread, maxval=signal_spread)\n",
    "y_train = tf.matmul(x_train, w_train) + b_train + tf.random.normal(shape=(n_train, 1), mean=0, stddev=noise_spread)\n",
    "y_train = tf.sigmoid(y_train)\n",
    "y_train = tf.cast(y_train > 0.5, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: cost=0.06730528175830841\n",
      "Epoch 199: cost=0.05774107202887535\n",
      "Epoch 299: cost=0.05373676121234894\n",
      "Epoch 399: cost=0.051511961966753006\n",
      "Epoch 499: cost=0.05010151490569115\n",
      "Epoch 599: cost=0.049135055392980576\n",
      "Epoch 699: cost=0.04843779280781746\n",
      "Epoch 799: cost=0.04791591316461563\n",
      "Epoch 899: cost=0.04751436784863472\n",
      "Epoch 999: cost=0.04719872400164604\n",
      "tf.Tensor(0.019, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.random.uniform(shape=(n_features, 1), minval=0, maxval=0.1))\n",
    "b = tf.Variable(tf.zeros(1))\n",
    "\n",
    "def loss(y, p):\n",
    "    l = -tf.reduce_mean(y * tf.math.log(p + 1e-16) + (1 - y) * tf.math.log(1 - p + 1e-16))\n",
    "    return l\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 1\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predict = tf.sigmoid(tf.matmul(x_train, w) + b)\n",
    "        c = loss(y_train, predict)\n",
    "        if (i + 1) % (n_epochs / 10) == 0:\n",
    "            print(f'Epoch {i}: cost={c}')\n",
    "    dw, db = tape.gradient(c, (w, b))\n",
    "    w.assign_sub(learning_rate * dw)\n",
    "    b.assign_sub(learning_rate * db)\n",
    "\n",
    "predict = tf.cast(tf.sigmoid(tf.matmul(x_train, w) + b) > 0.5, tf.float32)\n",
    "print(tf.reduce_mean(tf.abs(y_train - predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(15.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.911]\n",
      " [0.922]\n",
      " [0.883]\n",
      " [0.89 ]\n",
      " [0.9  ]], shape=(5, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(w_train / w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "num_samples_per_class = 1000\n",
    "\n",
    "neg_samples = np.random.multivariate_normal(\n",
    "    mean=[0, 3],\n",
    "    cov=[[1, 0.5],\n",
    "         [0.5, 1]],\n",
    "    size=num_samples_per_class)\n",
    "\n",
    "pos_samples = np.random.multivariate_normal(\n",
    "    mean=[3, 0],\n",
    "    cov=[[1, 0.5],\n",
    "         [0.5, 1]],\n",
    "    size=num_samples_per_class\n",
    ")\n",
    "\n",
    "x_train = np.vstack((neg_samples, pos_samples)).astype(np.float32)\n",
    "y_train = np.vstack((np.zeros((num_samples_per_class, 1), dtype=np.float32), np.ones((num_samples_per_class, 1), dtype=np.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss=3.3710\n",
      "Step 1: loss=0.4219\n",
      "Step 2: loss=0.1664\n",
      "Step 3: loss=0.1185\n",
      "Step 4: loss=0.1049\n",
      "Step 5: loss=0.0973\n",
      "Step 6: loss=0.0912\n",
      "Step 7: loss=0.0857\n",
      "Step 8: loss=0.0807\n",
      "Step 9: loss=0.0761\n",
      "Step 10: loss=0.0719\n",
      "Step 11: loss=0.0681\n",
      "Step 12: loss=0.0645\n",
      "Step 13: loss=0.0612\n",
      "Step 14: loss=0.0583\n",
      "Step 15: loss=0.0555\n",
      "Step 16: loss=0.0530\n",
      "Step 17: loss=0.0507\n",
      "Step 18: loss=0.0486\n",
      "Step 19: loss=0.0466\n",
      "Step 20: loss=0.0449\n",
      "Step 21: loss=0.0432\n",
      "Step 22: loss=0.0417\n",
      "Step 23: loss=0.0403\n",
      "Step 24: loss=0.0391\n",
      "Step 25: loss=0.0379\n",
      "Step 26: loss=0.0368\n",
      "Step 27: loss=0.0359\n",
      "Step 28: loss=0.0350\n",
      "Step 29: loss=0.0341\n",
      "Step 30: loss=0.0334\n",
      "Step 31: loss=0.0327\n",
      "Step 32: loss=0.0321\n",
      "Step 33: loss=0.0315\n",
      "Step 34: loss=0.0309\n",
      "Step 35: loss=0.0305\n",
      "Step 36: loss=0.0300\n",
      "Step 37: loss=0.0296\n",
      "Step 38: loss=0.0292\n",
      "Step 39: loss=0.0289\n"
     ]
    }
   ],
   "source": [
    "input_dim = 2\n",
    "output_dim = 1\n",
    "\n",
    "w = tf.Variable(initial_value = tf.random.uniform(shape=(input_dim, output_dim)))\n",
    "b = tf.Variable(initial_value= tf.zeros(shape=(output_dim,)))\n",
    "\n",
    "def model(x_train):\n",
    "    return tf.matmul(x_train, w) + b\n",
    "\n",
    "def sq_loss(y_train, predict):\n",
    "    return tf.reduce_mean(tf.square(y_train - predict))\n",
    "\n",
    "learning_rate = 0.1\n",
    "def training_step(x_train, y_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predict = model(x_train)\n",
    "        loss = sq_loss(y_train, predict)\n",
    "    dw, db = tape.gradient(loss, (w, b))\n",
    "    w.assign_sub(learning_rate * dw)\n",
    "    b.assign_sub(learning_rate * db)\n",
    "    return loss\n",
    "\n",
    "for step in range(40):\n",
    "    loss = training_step(x_train, y_train)\n",
    "    print(f'Step {step}: loss={loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
