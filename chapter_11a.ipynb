{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
     ]
    }
   ],
   "source": [
    "#!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "#!tar -xf aclImdb_v1.tar.gz\n",
    "#!rm -r aclImdb/train/unsup\n",
    "!cat aclImdb/train/pos/4077_10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "if False:\n",
    "    base_dir = pathlib.Path('aclImdb')\n",
    "    val_dir = base_dir / 'val'\n",
    "    train_dir = base_dir / 'train'\n",
    "    for category in ('neg', 'pos'):\n",
    "        os.makedirs(val_dir / category)\n",
    "        files = os.listdir(train_dir / category)\n",
    "        random.Random(1337).shuffle(files)\n",
    "        n_val_samples = int(0.2 * len(files))\n",
    "        val_files = files[-n_val_samples:]\n",
    "        for filename in val_files:\n",
    "            shutil.move(train_dir / category / filename, val_dir / category / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/val', batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/test', batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,) <dtype: 'string'> tf.Tensor(b'So much is wrong with this abysmal little wet fart of a movie that it\\'s hard to know where to begin.<br /><br />First of all, it\\'s a remarkably un-scary scary movie, even by Amercian standards. The dialogue is clich\\xc3\\xa9, the characters are two-dimensional, the writing is ho-hum, and what little story there is is neither coherent nor remotely interesting.<br /><br />We meet the following stereotypes in order: Balding Loser Guy (probably divorced, but who knows? This movie doesn\\'t tell us) with a brave heart, the Young Hero (who doesn\\'t do anything heroic at all), Brave Little Kid (with a homicidal streak a mile wide) and Black Bad-Ass Bitch (with more brawn than brains). These guys take up an ongoing fight with the Tall Scary Reaper Man and his evil Ewoks.<br /><br />Oh, and the film is full of wicked little metal orbs whoosing around menacing people. Given a chance, they perform impromptu brain surgery on those who doen\\'t have the mental acuity to duck when they come at them. Booh! Actually, one of them is haunted by a good ghost (but then again, it might be a deceitful spectre) who seems intent on helping our Brave Contagonists retrieve their young kidnapped friend.<br /><br />There is no character background or even an introduction to any of the characters. It starts with some kind of recap of the ending of the previous movie, but this doesn\\'t explain a lot. If you\\'ve seen the first two movies, fine. Otherwise you don\\'t know who these people are, how they are related, why they aren\\'t in school or at work, or why you should care whether they live or die. Consequently, you don\\'t. The only point of interest becomes any splatter effects. And there aren\\'t enough of those to keep you awake.<br /><br />Of potenial interest/amusement are the three Raider Punks, as stupid as they are evil, who menace Our Heroes. But they don\\'t get much screen time. They are offed almost immediately. Then they are buried (why anybody should take the time is beyond me), then they appear again as Evil Raider Punk Zombies. Only to be offed again, literally within a minute.<br /><br />The rest of the movie mainly seems to consist of Caspar the Friendly Ghost appearing and disappearing, driving around looking for places, and Balding Loser trying to score som Bad Black Bitch Booty, using pickup lines that would embarrass a mentally retarded teenager. No dice there; not even some gratuitous sex could have saved this movie, so good thing there never is any.<br /><br />The head baddie, called the Tall Man, doesn\\'t manage to scare anyone older than 3 years; howling \"Booooy!\" every five minutes isn\\'t enough. Why he, with his amazing telekinetic powers and uncanny upper-body strength, doesn\\'t simply squash our heroes like bugs isn\\'t explained. Instead, he delegates the job to his inept retarded little minions, who never manage to kill anyone before being shot to hell.<br /><br />Filmgoers who like masterpieces like \"Friday 13th part XXXXVIII: Jason goes to college\" might find some entertainment. The rest of us, who have developed pubic hair, will be bored out of our skulls.', shape=(), dtype=string)\n",
      "(32,) <dtype: 'int32'> tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(inputs.shape, inputs.dtype, inputs[0])\n",
    "    print(targets.shape, targets.dtype, targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "text_vectorization = layers.TextVectorization(max_tokens=20000, output_mode='multi_hot')\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "binary_1gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)\n",
    "binary_1gram_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)\n",
    "binary_1gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 20000) <dtype: 'float32'> tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
      "(32,) <dtype: 'int32'> tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in binary_1gram_train_ds:\n",
    "    print(inputs.shape, inputs.dtype, inputs[0])\n",
    "    print(targets.shape, targets.dtype, targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers, activations, optimizers, losses, metrics, callbacks\n",
    "\n",
    "def get_model(max_tokens=20000, hidden_dim=16):\n",
    "    inputs = layers.Input(shape=(max_tokens,))\n",
    "    x = layers.Dense(hidden_dim, activation=activations.relu)(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizers.RMSprop(), loss=losses.BinaryCrossentropy(), metrics=[metrics.BinaryAccuracy()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320033 (1.22 MB)\n",
      "Trainable params: 320033 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "605/625 [============================>.] - ETA: 0s - loss: 0.4079 - binary_accuracy: 0.8250INFO:tensorflow:Assets written to: binary_1gram/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: binary_1gram/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 2ms/step - loss: 0.4054 - binary_accuracy: 0.8264 - val_loss: 0.2701 - val_binary_accuracy: 0.8956\n",
      "Epoch 2/10\n",
      "598/625 [===========================>..] - ETA: 0s - loss: 0.2763 - binary_accuracy: 0.8965INFO:tensorflow:Assets written to: binary_1gram/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: binary_1gram/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2757 - binary_accuracy: 0.8970 - val_loss: 0.2637 - val_binary_accuracy: 0.9002\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2431 - binary_accuracy: 0.9150 - val_loss: 0.2766 - val_binary_accuracy: 0.9006\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2320 - binary_accuracy: 0.9218 - val_loss: 0.2890 - val_binary_accuracy: 0.8972\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2252 - binary_accuracy: 0.9254 - val_loss: 0.3003 - val_binary_accuracy: 0.8984\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2172 - binary_accuracy: 0.9271 - val_loss: 0.3084 - val_binary_accuracy: 0.8942\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2213 - binary_accuracy: 0.9309 - val_loss: 0.3193 - val_binary_accuracy: 0.8924\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2117 - binary_accuracy: 0.9316 - val_loss: 0.3195 - val_binary_accuracy: 0.8976\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2160 - binary_accuracy: 0.9341 - val_loss: 0.3253 - val_binary_accuracy: 0.8952\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2123 - binary_accuracy: 0.9355 - val_loss: 0.3374 - val_binary_accuracy: 0.8962\n",
      "782/782 [==============================] - 1s 899us/step - loss: 0.2886 - binary_accuracy: 0.8890\n",
      "[0.28864094614982605, 0.8889999985694885]\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "callback_list = [\n",
    "    callbacks.ModelCheckpoint('binary_1gram', save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(binary_1gram_train_ds, epochs=10, validation_data=binary_1gram_val_ds, callbacks=callback_list)\n",
    "\n",
    "model = keras.models.load_model('binary_1gram')\n",
    "print(model.evaluate(binary_1gram_test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = layers.TextVectorization(ngrams=2, max_tokens=20000, output_mode='multi_hot')\n",
    "text_vectorization.adapt(text_only_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "617/625 [============================>.] - ETA: 0s - loss: 0.3904 - binary_accuracy: 0.8384INFO:tensorflow:Assets written to: binary_2gram/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: binary_2gram/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 2ms/step - loss: 0.3889 - binary_accuracy: 0.8393 - val_loss: 0.2497 - val_binary_accuracy: 0.9040\n",
      "Epoch 2/10\n",
      "608/625 [============================>.] - ETA: 0s - loss: 0.2464 - binary_accuracy: 0.9136INFO:tensorflow:Assets written to: binary_2gram/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: binary_2gram/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2469 - binary_accuracy: 0.9136 - val_loss: 0.2478 - val_binary_accuracy: 0.9092\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2103 - binary_accuracy: 0.9321 - val_loss: 0.2554 - val_binary_accuracy: 0.9090\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1928 - binary_accuracy: 0.9362 - val_loss: 0.2784 - val_binary_accuracy: 0.9076\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1921 - binary_accuracy: 0.9433 - val_loss: 0.2818 - val_binary_accuracy: 0.9092\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1777 - binary_accuracy: 0.9442 - val_loss: 0.2969 - val_binary_accuracy: 0.9054\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1856 - binary_accuracy: 0.9474 - val_loss: 0.3031 - val_binary_accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1779 - binary_accuracy: 0.9496 - val_loss: 0.3132 - val_binary_accuracy: 0.9072\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1805 - binary_accuracy: 0.9484 - val_loss: 0.3203 - val_binary_accuracy: 0.9020\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1804 - binary_accuracy: 0.9490 - val_loss: 0.3241 - val_binary_accuracy: 0.8974\n",
      "782/782 [==============================] - 1s 886us/step - loss: 0.2653 - binary_accuracy: 0.9013\n",
      "[0.26531222462654114, 0.9013199806213379]\n"
     ]
    }
   ],
   "source": [
    "binary_2gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)\n",
    "binary_2gram_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)\n",
    "binary_2gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)\n",
    "\n",
    "model = get_model()\n",
    "callback_list = [\n",
    "    callbacks.ModelCheckpoint('binary_2gram', save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(binary_2gram_train_ds, validation_data=binary_2gram_val_ds, epochs=10, callbacks=callback_list)\n",
    "\n",
    "model = keras.models.load_model('binary_2gram')\n",
    "print(model.evaluate(binary_2gram_test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = layers.TextVectorization(ngrams=2, max_tokens=20000, output_mode='tf_idf')\n",
    "text_vectorization.adapt(text_only_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "610/625 [============================>.] - ETA: 0s - loss: 0.5574 - binary_accuracy: 0.7677INFO:tensorflow:Assets written to: tfidf_2gram/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfidf_2gram/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 2ms/step - loss: 0.5539 - binary_accuracy: 0.7700 - val_loss: 0.3117 - val_binary_accuracy: 0.8922\n",
      "Epoch 2/10\n",
      "602/625 [===========================>..] - ETA: 0s - loss: 0.3586 - binary_accuracy: 0.8596INFO:tensorflow:Assets written to: tfidf_2gram/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfidf_2gram/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8598 - val_loss: 0.2766 - val_binary_accuracy: 0.8900\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3220 - binary_accuracy: 0.8719 - val_loss: 0.2956 - val_binary_accuracy: 0.8724\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2977 - binary_accuracy: 0.8839 - val_loss: 0.2967 - val_binary_accuracy: 0.8746\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2876 - binary_accuracy: 0.8892 - val_loss: 0.3007 - val_binary_accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2629 - binary_accuracy: 0.8973 - val_loss: 0.3053 - val_binary_accuracy: 0.8948\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2555 - binary_accuracy: 0.9041 - val_loss: 0.3097 - val_binary_accuracy: 0.8928\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2492 - binary_accuracy: 0.9046 - val_loss: 0.3275 - val_binary_accuracy: 0.8820\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2425 - binary_accuracy: 0.9073 - val_loss: 0.3298 - val_binary_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.2365 - binary_accuracy: 0.9090 - val_loss: 0.3350 - val_binary_accuracy: 0.8788\n",
      "782/782 [==============================] - 1s 805us/step - loss: 0.2972 - binary_accuracy: 0.8798\n",
      "[0.2972339391708374, 0.8797600269317627]\n"
     ]
    }
   ],
   "source": [
    "tfidf_2gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)\n",
    "tfidf_2gram_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)\n",
    "tfidf_2gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)\n",
    "\n",
    "callback_list = [\n",
    "    callbacks.ModelCheckpoint('tfidf_2gram', save_best_only=True)\n",
    "]\n",
    "\n",
    "model = get_model()\n",
    "model.fit(tfidf_2gram_train_ds.cache(), validation_data=tfidf_2gram_val_ds, epochs=10, callbacks=callback_list)\n",
    "\n",
    "model = keras.models.load_model('tfidf_2gram')\n",
    "print(model.evaluate(tfidf_2gram_test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "\n",
    "text_vectorization = layers.TextVectorization(max_tokens=max_tokens, output_mode='int', output_sequence_length=max_length)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " tf.one_hot (TFOpLambda)     (None, None, 20000)       0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 64)                5128448   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5128513 (19.56 MB)\n",
      "Trainable params: 5128513 (19.56 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5302 - binary_accuracy: 0.7462INFO:tensorflow:Assets written to: one_hot_bidir_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_hot_bidir_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 973s 2s/step - loss: 0.5302 - binary_accuracy: 0.7462 - val_loss: 0.3526 - val_binary_accuracy: 0.8722\n",
      "782/782 [==============================] - 594s 760ms/step - loss: 0.3816 - binary_accuracy: 0.8532\n",
      "[0.38155484199523926, 0.8532000184059143]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=tf.int64)\n",
    "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=optimizers.RMSprop(), loss=losses.BinaryCrossentropy(), metrics=[metrics.BinaryAccuracy()])\n",
    "model.summary()\n",
    "\n",
    "callback_list = [\n",
    "    callbacks.ModelCheckpoint('one_hot_bidir_lstm', save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=1, callbacks=callback_list)\n",
    "\n",
    "model = keras.models.load_model('one_hot_bidir_lstm')\n",
    "print(model.evaluate(int_test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " tf.one_hot_1 (TFOpLambda)   (None, None, 20000)       0         \n",
      "                                                                 \n",
      " separable_conv1d (Separabl  (None, None, 64)          1340064   \n",
      " eConv1D)                                                        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, None, 64)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " separable_conv1d_1 (Separa  (None, None, 64)          4352      \n",
      " bleConv1D)                                                      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, None, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 64)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1344481 (5.13 MB)\n",
      "Trainable params: 1344481 (5.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4974INFO:tensorflow:Assets written to: one_hot_conv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_hot_conv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 439s 702ms/step - loss: 0.6932 - binary_accuracy: 0.4974 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "782/782 [==============================] - 191s 244ms/step - loss: 0.6931 - binary_accuracy: 0.5000\n",
      "[0.693149209022522, 0.5]\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None,), dtype=tf.int64)\n",
    "x = tf.one_hot(inputs, depth=max_tokens)\n",
    "x = layers.SeparableConv1D(filters=64, kernel_size=3, activation=activations.relu)(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.SeparableConv1D(filters=64, kernel_size=3, activation=activations.relu)(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=optimizers.RMSprop(), loss=losses.BinaryCrossentropy(), metrics=[metrics.BinaryAccuracy()])\n",
    "model.summary()\n",
    "\n",
    "callback_list = [\n",
    "    callbacks.ModelCheckpoint('one_hot_conv', save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=1, callbacks=callback_list)\n",
    "\n",
    "model = keras.models.load_model('one_hot_conv')\n",
    "print(model.evaluate(int_test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5048 - binary_accuracy: 0.7656INFO:tensorflow:Assets written to: embeddings_bidir_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embeddings_bidir_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 84s 133ms/step - loss: 0.5048 - binary_accuracy: 0.7656 - val_loss: 0.3292 - val_binary_accuracy: 0.8718\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3267 - binary_accuracy: 0.8838INFO:tensorflow:Assets written to: embeddings_bidir_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embeddings_bidir_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 83s 133ms/step - loss: 0.3267 - binary_accuracy: 0.8838 - val_loss: 0.3270 - val_binary_accuracy: 0.8826\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 81s 129ms/step - loss: 0.2493 - binary_accuracy: 0.9111 - val_loss: 0.3371 - val_binary_accuracy: 0.8850\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 83s 133ms/step - loss: 0.2184 - binary_accuracy: 0.9255 - val_loss: 0.3790 - val_binary_accuracy: 0.8476\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1805 - binary_accuracy: 0.9391INFO:tensorflow:Assets written to: embeddings_bidir_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embeddings_bidir_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 89s 143ms/step - loss: 0.1805 - binary_accuracy: 0.9391 - val_loss: 0.3008 - val_binary_accuracy: 0.8866\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 81s 129ms/step - loss: 0.1587 - binary_accuracy: 0.9496 - val_loss: 0.3678 - val_binary_accuracy: 0.8722\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 79s 127ms/step - loss: 0.1373 - binary_accuracy: 0.9552 - val_loss: 0.3325 - val_binary_accuracy: 0.8904\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 82s 131ms/step - loss: 0.1221 - binary_accuracy: 0.9597 - val_loss: 0.3690 - val_binary_accuracy: 0.8836\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 80s 128ms/step - loss: 0.1040 - binary_accuracy: 0.9663 - val_loss: 0.3578 - val_binary_accuracy: 0.8766\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 79s 127ms/step - loss: 0.0936 - binary_accuracy: 0.9707 - val_loss: 0.3862 - val_binary_accuracy: 0.8834\n",
      "782/782 [==============================] - 20s 26ms/step - loss: 0.3998 - binary_accuracy: 0.8520\n",
      "[0.39976829290390015, 0.8519600033760071]\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(None,), dtype=tf.int64)\n",
    "embbedded = layers.Embedding(input_dim=max_tokens, output_dim=128)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(units=32))(embbedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(), loss=losses.BinaryCrossentropy(), metrics=[metrics.BinaryAccuracy()])\n",
    "\n",
    "callback_list = [\n",
    "    callbacks.ModelCheckpoint('embeddings_bidir_lstm', save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callback_list)\n",
    "model = keras.models.load_model('embeddings_bidir_lstm')\n",
    "print(model.evaluate(int_test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4053 - binary_accuracy: 0.8127INFO:tensorflow:Assets written to: embeddings_bidir_lstm_masking/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embeddings_bidir_lstm_masking/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 110s 172ms/step - loss: 0.4053 - binary_accuracy: 0.8127 - val_loss: 0.2826 - val_binary_accuracy: 0.8910\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2450 - binary_accuracy: 0.9064INFO:tensorflow:Assets written to: embeddings_bidir_lstm_masking/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embeddings_bidir_lstm_masking/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 102s 164ms/step - loss: 0.2450 - binary_accuracy: 0.9064 - val_loss: 0.2809 - val_binary_accuracy: 0.8920\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 98s 156ms/step - loss: 0.1812 - binary_accuracy: 0.9331 - val_loss: 0.3054 - val_binary_accuracy: 0.8926\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 98s 156ms/step - loss: 0.1404 - binary_accuracy: 0.9486 - val_loss: 0.3428 - val_binary_accuracy: 0.8910\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 98s 157ms/step - loss: 0.1104 - binary_accuracy: 0.9618 - val_loss: 0.3024 - val_binary_accuracy: 0.8836\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 100s 160ms/step - loss: 0.0852 - binary_accuracy: 0.9703 - val_loss: 0.3545 - val_binary_accuracy: 0.8920\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 96s 153ms/step - loss: 0.0622 - binary_accuracy: 0.9789 - val_loss: 0.3745 - val_binary_accuracy: 0.8918\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 96s 153ms/step - loss: 0.0490 - binary_accuracy: 0.9839 - val_loss: 0.4122 - val_binary_accuracy: 0.8930\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 96s 154ms/step - loss: 0.0349 - binary_accuracy: 0.9887 - val_loss: 0.4760 - val_binary_accuracy: 0.8880\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 96s 154ms/step - loss: 0.0263 - binary_accuracy: 0.9918 - val_loss: 0.5089 - val_binary_accuracy: 0.8856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 14:52:56.106021: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:56.181669: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:56.628445: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:56.633595: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:56.671454: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:56.941361: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:56.983666: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.031775: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.052390: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.060764: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.065651: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.220915: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.486025: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.555915: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.560363: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.591645: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.596014: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.613715: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.618555: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 14:52:57.763494: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 24s 30ms/step - loss: 0.3484 - binary_accuracy: 0.8704\n",
      "[0.3483661413192749, 0.8703600168228149]\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(None,), dtype=tf.int64)\n",
    "embbedded = layers.Embedding(input_dim=max_tokens, output_dim=128, mask_zero=True)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(units=32))(embbedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(), loss=losses.BinaryCrossentropy(), metrics=[metrics.BinaryAccuracy()])\n",
    "\n",
    "callback_list = [\n",
    "    callbacks.ModelCheckpoint('embeddings_bidir_lstm_masking', save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callback_list)\n",
    "model = keras.models.load_model('embeddings_bidir_lstm_masking')\n",
    "print(model.evaluate(int_test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "path_to_glove_file = 'glove.6B.100d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.17083003,  0.59597003,  0.59098995,  0.02536997,  0.61793995,\n",
       "       -0.19281995, -0.089395  ,  0.63546395, -0.21893004,  0.87589   ,\n",
       "        0.138769  , -0.25664997, -0.27886   ,  0.19888899,  0.482831  ,\n",
       "        0.00455004, -0.53747606,  0.03740007, -0.17844999, -0.8905601 ,\n",
       "       -0.53164005,  0.51741993,  0.50496995, -1.15989   , -0.35557997,\n",
       "       -0.32298994, -0.39193   , -0.02756   ,  0.81107   ,  0.00885099,\n",
       "       -0.10747302, -0.04339998,  0.23818994,  0.06065002, -0.07598999,\n",
       "        0.09676903, -0.34658   ,  0.28506997, -0.982826  , -0.00301   ,\n",
       "        0.41085   , -0.17233601, -0.01127499, -0.16784   ,  0.99841   ,\n",
       "        0.09046301, -0.03593001, -0.24147004, -0.21476996,  0.13638696,\n",
       "        0.1085    , -0.41917497, -0.54655004,  0.06991002, -0.47669   ,\n",
       "       -0.28980005, -0.09448004, -0.71713   , -0.19064   , -0.181496  ,\n",
       "       -0.36639   , -0.48315996, -0.01811402,  0.109236  ,  0.398004  ,\n",
       "       -0.08116996,  0.21427998,  0.09854996,  0.553653  ,  0.13898697,\n",
       "        0.065202  , -0.02931005, -0.14325699, -0.43077093,  0.03149998,\n",
       "       -0.18541904,  0.32904008,  0.01292601,  1.1459291 , -0.28129005,\n",
       "        0.14667499,  0.45740998,  0.53185993, -0.33542097, -0.22841996,\n",
       "       -0.47275007,  0.03123999,  0.10539001,  0.38956   , -0.12832004,\n",
       "       -0.12122899, -0.11925   , -0.18084297,  0.16954002,  0.06617999,\n",
       "        0.363114  , -0.56505   ,  0.21383002, -0.269479  , -0.07526994],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeddings_index['queen'] - embeddings_index['king']) - (embeddings_index['princess'] - embeddings_index['prince'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_tokens:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(\n",
    "    input_dim=max_tokens,\n",
    "    output_dim=embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    "    mask_zero=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, None, 100)         2000000   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 64)                34048     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2034113 (7.76 MB)\n",
      "Trainable params: 34113 (133.25 KB)\n",
      "Non-trainable params: 2000000 (7.63 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5703 - binary_accuracy: 0.6988INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 90s 140ms/step - loss: 0.5703 - binary_accuracy: 0.6988 - val_loss: 0.4237 - val_binary_accuracy: 0.8090\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 76s 121ms/step - loss: 0.4463 - binary_accuracy: 0.7965 - val_loss: 0.4770 - val_binary_accuracy: 0.7664\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4019 - binary_accuracy: 0.8241INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 85s 137ms/step - loss: 0.4019 - binary_accuracy: 0.8241 - val_loss: 0.3656 - val_binary_accuracy: 0.8360\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3674 - binary_accuracy: 0.8433INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 85s 136ms/step - loss: 0.3674 - binary_accuracy: 0.8433 - val_loss: 0.3565 - val_binary_accuracy: 0.8460\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3449 - binary_accuracy: 0.8536INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 84s 135ms/step - loss: 0.3449 - binary_accuracy: 0.8536 - val_loss: 0.3060 - val_binary_accuracy: 0.8742\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 74s 118ms/step - loss: 0.3258 - binary_accuracy: 0.8637 - val_loss: 0.3075 - val_binary_accuracy: 0.8680\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3055 - binary_accuracy: 0.8736INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 84s 135ms/step - loss: 0.3055 - binary_accuracy: 0.8736 - val_loss: 0.2868 - val_binary_accuracy: 0.8818\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 74s 118ms/step - loss: 0.2906 - binary_accuracy: 0.8824 - val_loss: 0.2925 - val_binary_accuracy: 0.8806\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 73s 117ms/step - loss: 0.2791 - binary_accuracy: 0.8880 - val_loss: 0.3084 - val_binary_accuracy: 0.8704\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2611 - binary_accuracy: 0.8953INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: glove_embeddings_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 83s 134ms/step - loss: 0.2611 - binary_accuracy: 0.8953 - val_loss: 0.2782 - val_binary_accuracy: 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 15:32:34.412863: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:34.485160: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:34.922968: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:35.560045: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:35.840708: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:35.845620: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:35.887372: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:35.891904: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:35.952603: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:35.956796: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:36.160865: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:36.165544: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:36.424818: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:36.429202: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:36.481728: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:36.486040: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:36.678163: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:36.682449: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:36.696851: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-09-21 15:32:36.701308: W tensorflow/core/common_runtime/graph_constructor.cc:834] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 23s 28ms/step - loss: 0.2957 - binary_accuracy: 0.8764\n",
      "[0.29573968052864075, 0.8763999938964844]\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(None,), dtype=tf.int64)\n",
    "embedded = embedding_layer(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=activations.sigmoid)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=optimizers.RMSprop(), loss=losses.BinaryCrossentropy(), metrics=[metrics.BinaryAccuracy()])\n",
    "model.summary()\n",
    "\n",
    "callback_list = [\n",
    "    callbacks.ModelCheckpoint('glove_embeddings_lstm', save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callback_list)\n",
    "\n",
    "\n",
    "model = keras.models.load_model('glove_embeddings_lstm')\n",
    "print(model.evaluate(int_test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
